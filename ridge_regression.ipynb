{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ridge Regression From Scratch\n",
    "\n",
    "First, we import numpy for the mathematical operations and pandas to load in the dataset we will test our model on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We create the RidgeRegression class. Alpha is the regularization rate. The following equation tells us how to calculate the weights, it is equivalent to the condition that $RSS(w)$ is minimal.\n",
    "\n",
    "$$w_{ols} = (X^{T}X + \\alpha I^{*})^{-1}Xy$$\n",
    "Also, as long as $\\alpha \\not= 0$, we know $X^{T}X + \\alpha I^{*}$ is always invertible. For any vector $x \\in R^{p+1}, x \\not = \\bold 0$, we can see\n",
    "\n",
    "$$x^{T}(X^{T}X + \\alpha I^{*})x = x^{T}X^{T}Xx + x^{T} \\alpha I^{*}x = ||Xx||^{2} + \\alpha \\sum^{p}_{i = 1} w^{2}_i > 0 $$\n",
    "\n",
    "$I^{*}$ is identity matrix except with 0 in the first row and first column, we do not want to penalize the intercept."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RidgeRegression:\n",
    "  def __init__(self, feature_count, alfa = 0):\n",
    "    self.weights = np.zeros(feature_count)\n",
    "    self.alfa = alfa\n",
    "\n",
    "  def predict(self, X_data):\n",
    "    X_data = np.hstack((np.ones((X_data.shape[0], 1)), X_data))\n",
    "    result = np.matmul(X_data, self.weights)\n",
    "    return result\n",
    "  \n",
    "  def fit(self, X_data, y_data):\n",
    "    X_data = np.hstack((np.ones((X_data.shape[0], 1)), X_data))\n",
    "\n",
    "    X = np.array(X_data)\n",
    "    y = np.array(y_data)\n",
    "\n",
    "    identity_matrix = np.eye(X.shape[1])\n",
    "    identity_matrix[0][0] = 0\n",
    "\n",
    "    self.weights = np.matmul(np.linalg.inv(np.matmul(X.T, X) + self.alfa * identity_matrix), np.matmul(X.T, y))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We download dataset where the target variable is price of a house. We are not going to go in depth explaining the dataset as it is not the goal of this project. We quickly check for any missing values and convert all non-numeric values to numeric represenations.\n",
    "\n",
    "Source: https://www.kaggle.com/datasets/yasserh/housing-prices-dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = pd.read_csv(\"Housing.csv\")\n",
    "dataset = dataset.sample(frac=1).reset_index(drop=True)\n",
    "dataset.replace({'yes': 1, 'no': 0, 'furnished' : 1, 'semi-furnished' : 2, 'unfurnished' : 3}, inplace=True)\n",
    "dataset.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We divide the dataset into training set and test set (80% to 20%), no need for a validation/dev set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_size = int(np.floor(0.8 * len(dataset)))\n",
    "\n",
    "X_train = dataset.iloc[:train_size].drop(columns=\"price\")\n",
    "y_train = dataset.iloc[:train_size][\"price\"]\n",
    "X_test = dataset.iloc[train_size:].drop(columns=\"price\")\n",
    "y_test = dataset.iloc[train_size:][\"price\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We finally try to fit our implementation with $\\alpha = 1$ and then we print out the $RMSE = \\sqrt{\\frac{1}{N} \\sum^{N}_{i=1}(Y_i - \\hat{Y}_i)^{2}}$, where $N$ is the number of data points. The RMSE seems fairly high, so let's check with sklearn implementation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE (alfa = 1): 1111927.384.\n"
     ]
    }
   ],
   "source": [
    "model = RidgeRegression(dataset.shape[1] - 1, 1)\n",
    "model.fit(X_train, y_train)\n",
    "RMSE = np.sqrt(sum((y_test - model.predict(X_test))**2) / len(y_test))\n",
    "print(f\"RMSE (alfa = {model.alfa}): {round(RMSE, 3)}.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We use the same $\\alpha$ and we can see the $RMSE$ is exactly the same, therefore our implementation is correct. The is most likely not tuning $\\alpha$ and not preprocessing the dataset in any way, we could definitely reach lower values of $RMSE$, but that is not the point of this project. Our implementation was successful."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE (alfa = 1): 1111927.384.\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import Ridge\n",
    "model = Ridge(1)\n",
    "model.fit(X_train, y_train)\n",
    "RMSE = np.sqrt(sum((y_test - model.predict(X_test))**2) / len(y_test))\n",
    "print(f\"RMSE (alfa = {1}): {round(RMSE, 3)}.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
